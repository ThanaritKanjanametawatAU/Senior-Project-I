{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import numpy as np\n",
    "combined_df = pd.read_csv('dataset/Combined-Preprocessed-Dataset.csv')\n",
    "combined_df = combined_df[['text', 'label']]\n",
    "\n",
    "combined_df = combined_df.groupby('label').apply(lambda x: x.sample(n=100, random_state=1)).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T12:02:46.546035300Z",
     "start_time": "2023-09-12T12:02:37.579034400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Tokenization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "input_ids = tokenizer.batch_encode_plus(combined_df['text'].tolist(), padding=True, truncation=True, return_tensors=\"pt\").input_ids\n",
    "labels = torch.tensor(combined_df['label'].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T12:02:48.550035Z",
     "start_time": "2023-09-12T12:02:47.947035600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 3. Dataset and DataLoader\n",
    "dataset = TensorDataset(input_ids, labels)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "batch_size = 16\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T12:02:48.794035200Z",
     "start_time": "2023-09-12T12:02:48.794035200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u6410322/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 4. Model Configuration\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n",
    "epoch = 5\n",
    "learning_rate = 5e-4\n",
    "weight_decay = 1e-3\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=epoch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T12:02:52.007034800Z",
     "start_time": "2023-09-12T12:02:48.794035200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [160, 81920]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 57\u001B[0m\n\u001B[1;32m     55\u001B[0m train_loss\u001B[38;5;241m.\u001B[39mappend(np\u001B[38;5;241m.\u001B[39mmean(train_loss_epoch))\n\u001B[1;32m     56\u001B[0m val_loss\u001B[38;5;241m.\u001B[39mappend(np\u001B[38;5;241m.\u001B[39mmean(val_loss_epoch))\n\u001B[0;32m---> 57\u001B[0m train_accuracy\u001B[38;5;241m.\u001B[39mappend(accuracy_score(train_true, train_preds))\n\u001B[1;32m     58\u001B[0m val_accuracy\u001B[38;5;241m.\u001B[39mappend(accuracy_score(val_true, val_preds))\n\u001B[1;32m     59\u001B[0m train_precision\u001B[38;5;241m.\u001B[39mappend(precision_score(train_true, train_preds, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweighted\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    209\u001B[0m         )\n\u001B[1;32m    210\u001B[0m     ):\n\u001B[0;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    221\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:220\u001B[0m, in \u001B[0;36maccuracy_score\u001B[0;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Accuracy classification score.\u001B[39;00m\n\u001B[1;32m    155\u001B[0m \n\u001B[1;32m    156\u001B[0m \u001B[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;124;03m0.5\u001B[39;00m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;66;03m# Compute accuracy for each possible representation\u001B[39;00m\n\u001B[0;32m--> 220\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m _check_targets(y_true, y_pred)\n\u001B[1;32m    221\u001B[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[1;32m    222\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:84\u001B[0m, in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_targets\u001B[39m(y_true, y_pred):\n\u001B[1;32m     58\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001B[39;00m\n\u001B[1;32m     59\u001B[0m \n\u001B[1;32m     60\u001B[0m \u001B[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;124;03m    y_pred : array or indicator matrix\u001B[39;00m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 84\u001B[0m     check_consistent_length(y_true, y_pred)\n\u001B[1;32m     85\u001B[0m     type_true \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     86\u001B[0m     type_pred \u001B[38;5;241m=\u001B[39m type_of_target(y_pred, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:409\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    407\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[1;32m    408\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 409\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    410\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    411\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[1;32m    412\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [160, 81920]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "train_precision = []\n",
    "val_precision = []\n",
    "train_recall = []\n",
    "val_recall = []\n",
    "train_f1 = []\n",
    "val_f1 = []\n",
    "\n",
    "for e in range(epoch):\n",
    "    model.train()\n",
    "    train_loss_epoch = []\n",
    "    train_preds = []\n",
    "    train_true = []\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, labels = batch\n",
    "        input_ids, labels = input_ids.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        train_loss_epoch.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Calculate train metrics\n",
    "        pred = torch.argmax(outputs.logits, dim=2)\n",
    "        train_preds.extend(pred.flatten().tolist())\n",
    "        train_true.extend(labels.flatten().tolist())\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss_epoch = []\n",
    "    val_preds = []\n",
    "    val_true = []\n",
    "    for batch in val_dataloader:\n",
    "        input_ids, labels = batch\n",
    "        input_ids, labels = input_ids.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        val_loss_epoch.append(loss.item())\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        pred = torch.argmax(outputs.logits, dim=2)\n",
    "        val_preds.extend(pred.flatten().tolist())\n",
    "        val_true.extend(labels.flatten().tolist())\n",
    "    \n",
    "    # Calculate and store metrics\n",
    "    train_loss.append(np.mean(train_loss_epoch))\n",
    "    val_loss.append(np.mean(val_loss_epoch))\n",
    "    train_accuracy.append(accuracy_score(train_true, train_preds))\n",
    "    val_accuracy.append(accuracy_score(val_true, val_preds))\n",
    "    train_precision.append(precision_score(train_true, train_preds, average='weighted'))\n",
    "    val_precision.append(precision_score(val_true, val_preds, average='weighted'))\n",
    "    train_recall.append(recall_score(train_true, train_preds, average='weighted'))\n",
    "    val_recall.append(recall_score(val_true, val_preds, average='weighted'))\n",
    "    train_f1.append(f1_score(train_true, train_preds, average='weighted'))\n",
    "    val_f1.append(f1_score(val_true, val_preds, average='weighted'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T12:03:00.881036Z",
     "start_time": "2023-09-12T12:02:52.003037400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 9. Plotting metrics\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracy, label='Train Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-12T12:03:00.880034800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 10. Evaluation\n",
    "\n",
    "# Final Metrics on Validation Set\n",
    "final_val_preds = []  # Store your final validation predictions here\n",
    "final_val_labels = []  # Store the actual labels here\n",
    "\n",
    "# Calculate basic metrics\n",
    "final_val_accuracy = accuracy_score(final_val_labels, final_val_preds)\n",
    "final_val_precision = precision_score(final_val_labels, final_val_preds, average='weighted')\n",
    "final_val_recall = recall_score(final_val_labels, final_val_preds, average='weighted')\n",
    "final_val_f1 = f1_score(final_val_labels, final_val_preds, average='weighted')\n",
    "\n",
    "print(f\"Final Validation Accuracy: {final_val_accuracy}\")\n",
    "print(f\"Final Validation Precision: {final_val_precision}\")\n",
    "print(f\"Final Validation Recall: {final_val_recall}\")\n",
    "print(f\"Final Validation F1 Score: {final_val_f1}\")\n",
    "\n",
    "# ROC and AUC\n",
    "fpr, tpr, _ = roc_curve(final_val_labels, final_val_preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# DET Curve\n",
    "fnr = 1 - tpr\n",
    "eer = brentq(lambda x : 1. - x - interp1d(fpr, fnr)(x), 0., 1.)\n",
    "thresh = interp1d(fpr, thresholds)(eer)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, fnr, label='EER = {:.3f}'.format(eer))\n",
    "plt.scatter(eer, 1-eer, c='red')\n",
    "plt.title('DET Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('False Negative Rate')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T12:03:00.881036Z",
     "start_time": "2023-09-12T12:03:00.881036Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-12T12:00:24.250236300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T12:00:24.251236500Z",
     "start_time": "2023-09-12T12:00:24.250236300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
