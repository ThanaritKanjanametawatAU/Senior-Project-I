{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **T5-Sentinel Model**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Train, Validation, and Test Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 The preprocessed dataset is read from the csv file. The extracted features are converted from string representation of lists into actual lists of numbers. The lists of numbers are then converted into numpy arrays. The labels are also converted into numpy arrays."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the data\n",
    "combined_df = pd.read_csv('dataset/Combined-Preprocessed-Dataset.csv')\n",
    "\n",
    "# # Convert the string representation of lists into actual lists of numbers\n",
    "# X = combined_df['extracted_features'].str.replace('\\n', '').str.strip('[]').str.split().apply(lambda x: [float(i) for i in x])\n",
    "#\n",
    "# # Convert lists of numbers into numpy arrays\n",
    "# X = np.array(X.tolist())\n",
    "#\n",
    "# # Get the labels as a numpy array\n",
    "# y = np.array(combined_df['label'].tolist())\n",
    "#\n",
    "# X, y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 The data is split into train, validation, and test sets. The train set is 67.5% of the data, the validation set is 12.5% of the data, and the test set is 20% of the data. Validation set is used to tune the hyperparameters of the model. The test set is used to evaluate the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u6410322/anaconda3/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW, get_cosine_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and preprocess data\n",
    "\n",
    "# Modify labels for T5 classification\n",
    "combined_df['t5_label'] = combined_df['label'].apply(lambda x: \"positive </s>\" if x == 1 else \"negative </s>\")\n",
    "\n",
    "# Initialize T5 tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to('cuda')\n",
    "\n",
    "# Encode texts and labels\n",
    "texts = combined_df['text'].tolist()\n",
    "labels = combined_df['t5_label'].tolist()\n",
    "\n",
    "input_encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\").to('cuda')\n",
    "label_encodings = tokenizer(labels, padding='max_length', max_length=2, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "\n",
    "# Convert input_encodings and label_encodings to tensors\n",
    "input_ids = input_encodings['input_ids']\n",
    "attention_masks = input_encodings['attention_mask']\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_inputs, test_inputs, train_masks, test_masks, train_labels, test_labels = train_test_split(input_ids, attention_masks, label_encodings, test_size=0.2)\n",
    "train_inputs, val_inputs, train_masks, val_masks, train_labels, val_labels = train_test_split(train_inputs, train_masks, train_labels, test_size=0.125)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T12:03:38.167040900Z",
     "start_time": "2023-08-29T12:01:18.090213900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Model Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u6410322/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 44\u001B[0m\n\u001B[1;32m     42\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(input_ids\u001B[38;5;241m=\u001B[39minput_batch, attention_mask\u001B[38;5;241m=\u001B[39mmask_batch, labels\u001B[38;5;241m=\u001B[39mlabel_batch)\n\u001B[1;32m     43\u001B[0m loss \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mloss\n\u001B[0;32m---> 44\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     45\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     46\u001B[0m scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[1;32m    488\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[1;32m    489\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    201\u001B[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001B[1;32m    202\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 5\n",
    "batch_size = 512\n",
    "learning_rate = 5e-4\n",
    "weight_decay = 1e-3\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_inputs) * epochs)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW, get_cosine_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Lists to store metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_precisions = []\n",
    "val_precisions = []\n",
    "train_f1s = []\n",
    "val_f1s = []\n",
    "\n",
    "# Fine-tune T5 model\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_preds, train_true = [], []\n",
    "\n",
    "    for i in range(0, len(train_inputs), batch_size):\n",
    "        input_batch = train_inputs[i:i+batch_size].to('cuda')\n",
    "        mask_batch = train_masks[i:i+batch_size].to('cuda')\n",
    "        label_batch = train_labels[i:i+batch_size].to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_batch, attention_mask=mask_batch, labels=label_batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        logits = outputs.logits.argmax(dim=-1)[:, 0].detach().cpu().numpy()  # Take the first token's predicted ID\n",
    "        labels = label_batch[:, 0].cpu().numpy()  # Take the first token's true ID\n",
    "        train_preds.extend(logits)\n",
    "        train_true.extend(labels)\n",
    "\n",
    "    # Calculate metrics for training\n",
    "    train_accuracy = accuracy_score(train_true, train_preds)\n",
    "    train_precision = precision_score(train_true, train_preds)\n",
    "    train_f1 = f1_score(train_true, train_preds)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds, val_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(val_inputs), batch_size):\n",
    "            input_batch = val_inputs[i:i+batch_size].to('cuda')\n",
    "            label_batch = val_labels[i:i+batch_size].to('cuda')\n",
    "            outputs = model(input_ids=input_batch, labels=label_batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "            # For accuracy, precision, f1\n",
    "            logits = outputs.logits.argmax(dim=-1)[:, 0].detach().cpu().numpy()  # Take the first token's predicted ID\n",
    "            labels = label_batch[:, 0].cpu().numpy()  # Take the first token's true ID\n",
    "            val_preds.extend(logits)\n",
    "            val_true.extend(labels)\n",
    "\n",
    "    # Calculate metrics for validation\n",
    "    val_accuracy = accuracy_score(val_true, val_preds)\n",
    "    val_precision = precision_score(val_true, val_preds)\n",
    "    val_f1 = f1_score(val_true, val_preds)\n",
    "\n",
    "    # Store metrics\n",
    "    train_losses.append(running_loss/len(train_inputs))\n",
    "    val_losses.append(val_loss/len(val_inputs))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    train_precisions.append(train_precision)\n",
    "    val_precisions.append(val_precision)\n",
    "    train_f1s.append(train_f1)\n",
    "    val_f1s.append(val_f1)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T12:35:23.835663800Z",
     "start_time": "2023-08-29T12:25:46.546083100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting metrics\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plotting Loss\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting Accuracy\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting Precision\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.plot(train_precisions, label='Train Precision')\n",
    "plt.plot(val_precisions, label='Val Precision')\n",
    "plt.title('Precision')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting F1 Score\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.plot(train_f1s, label='Train F1')\n",
    "plt.plot(val_f1s, label='Val F1')\n",
    "plt.title('F1 Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "# Evaluate the model on the test set\n",
    "test_preds, test_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_inputs), batch_size):\n",
    "        input_batch = test_inputs[i:i+batch_size].to('cuda')\n",
    "        label_batch = test_labels[i:i+batch_size].to('cuda')\n",
    "\n",
    "        outputs = model(input_ids=input_batch, labels=label_batch)\n",
    "        # For accuracy, precision, f1\n",
    "        logits = outputs.logits.argmax(dim=-1)[:, 0].detach().cpu().numpy()  # Take the first token's predicted ID\n",
    "        labels = label_batch[:, 0].cpu().numpy()  # Take the first token's true ID\n",
    "        test_preds.extend(logits)\n",
    "        test_true.extend(labels)\n",
    "\n",
    "# Calculate metrics for test set\n",
    "test_accuracy = accuracy_score(test_true, test_preds)\n",
    "test_precision = precision_score(test_true, test_preds)\n",
    "test_recall = recall_score(test_true, test_preds)\n",
    "test_f1 = f1_score(test_true, test_preds)\n",
    "tn, fp, fn, tp = confusion_matrix(test_true, test_preds).ravel()\n",
    "fpr = fp / (fp + tn)\n",
    "fnr = fn / (fn + tp)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "print(f\"False Positive Rate (FPR): {fpr:.4f}\")\n",
    "print(f\"False Negative Rate (FNR): {fnr:.4f}\")\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "import seaborn as sns\n",
    "confusion = confusion_matrix(test_true, test_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ROC Curve & AUC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "test_true_bin = label_binarize(test_true, classes=[0, 1])\n",
    "test_preds_bin = label_binarize(test_preds, classes=[0, 1])\n",
    "fpr_roc, tpr_roc, _ = roc_curve(test_true_bin, test_preds_bin)\n",
    "roc_auc = auc(fpr_roc, tpr_roc)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_roc, tpr_roc, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DET Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, fnr, color='darkorange', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('False Negative Rate')\n",
    "plt.title('Detection Error Tradeoff (DET) Curve')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 't5_sentinel_model.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
